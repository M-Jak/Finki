{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v8vsWahSyK_i"
   },
   "source": [
    "# Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G4FVV4npyYwk"
   },
   "source": [
    "## Building the Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oY3xhC9YZsO8"
   },
   "source": [
    "Use the following dataset https://www.kaggle.com/datasets/anmolkumar/health-insurance-cross-sell-prediction?select=train.csv to build three different neural networks using\n",
    "\n",
    "> different layers\n",
    "\n",
    "\n",
    "> activation functions\n",
    "\n",
    "\n",
    "> number of neurons per layer\n",
    "\n",
    "\n",
    "> number of layers\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import keras\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder, OrdinalEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('./train.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MOJGKW_9auD4"
   },
   "source": [
    "### Data pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "id": "UR3dEMr-atq7"
   },
   "outputs": [],
   "source": [
    "data = data.drop(columns='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Driving_License</th>\n",
       "      <th>Region_Code</th>\n",
       "      <th>Previously_Insured</th>\n",
       "      <th>Vehicle_Age</th>\n",
       "      <th>Vehicle_Damage</th>\n",
       "      <th>Annual_Premium</th>\n",
       "      <th>Policy_Sales_Channel</th>\n",
       "      <th>Vintage</th>\n",
       "      <th>Response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Male</td>\n",
       "      <td>44</td>\n",
       "      <td>1</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0</td>\n",
       "      <td>&gt; 2 Years</td>\n",
       "      <td>Yes</td>\n",
       "      <td>40454.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>217</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Male</td>\n",
       "      <td>76</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1-2 Year</td>\n",
       "      <td>No</td>\n",
       "      <td>33536.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>183</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Male</td>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0</td>\n",
       "      <td>&gt; 2 Years</td>\n",
       "      <td>Yes</td>\n",
       "      <td>38294.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Male</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1</td>\n",
       "      <td>&lt; 1 Year</td>\n",
       "      <td>No</td>\n",
       "      <td>28619.0</td>\n",
       "      <td>152.0</td>\n",
       "      <td>203</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Female</td>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "      <td>41.0</td>\n",
       "      <td>1</td>\n",
       "      <td>&lt; 1 Year</td>\n",
       "      <td>No</td>\n",
       "      <td>27496.0</td>\n",
       "      <td>152.0</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>381104</th>\n",
       "      <td>Male</td>\n",
       "      <td>74</td>\n",
       "      <td>1</td>\n",
       "      <td>26.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1-2 Year</td>\n",
       "      <td>No</td>\n",
       "      <td>30170.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>88</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>381105</th>\n",
       "      <td>Male</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>37.0</td>\n",
       "      <td>1</td>\n",
       "      <td>&lt; 1 Year</td>\n",
       "      <td>No</td>\n",
       "      <td>40016.0</td>\n",
       "      <td>152.0</td>\n",
       "      <td>131</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>381106</th>\n",
       "      <td>Male</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1</td>\n",
       "      <td>&lt; 1 Year</td>\n",
       "      <td>No</td>\n",
       "      <td>35118.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>161</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>381107</th>\n",
       "      <td>Female</td>\n",
       "      <td>68</td>\n",
       "      <td>1</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0</td>\n",
       "      <td>&gt; 2 Years</td>\n",
       "      <td>Yes</td>\n",
       "      <td>44617.0</td>\n",
       "      <td>124.0</td>\n",
       "      <td>74</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>381108</th>\n",
       "      <td>Male</td>\n",
       "      <td>46</td>\n",
       "      <td>1</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1-2 Year</td>\n",
       "      <td>No</td>\n",
       "      <td>41777.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>237</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>381109 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Gender  Age  Driving_License  Region_Code  Previously_Insured  \\\n",
       "0         Male   44                1         28.0                   0   \n",
       "1         Male   76                1          3.0                   0   \n",
       "2         Male   47                1         28.0                   0   \n",
       "3         Male   21                1         11.0                   1   \n",
       "4       Female   29                1         41.0                   1   \n",
       "...        ...  ...              ...          ...                 ...   \n",
       "381104    Male   74                1         26.0                   1   \n",
       "381105    Male   30                1         37.0                   1   \n",
       "381106    Male   21                1         30.0                   1   \n",
       "381107  Female   68                1         14.0                   0   \n",
       "381108    Male   46                1         29.0                   0   \n",
       "\n",
       "       Vehicle_Age Vehicle_Damage  Annual_Premium  Policy_Sales_Channel  \\\n",
       "0        > 2 Years            Yes         40454.0                  26.0   \n",
       "1         1-2 Year             No         33536.0                  26.0   \n",
       "2        > 2 Years            Yes         38294.0                  26.0   \n",
       "3         < 1 Year             No         28619.0                 152.0   \n",
       "4         < 1 Year             No         27496.0                 152.0   \n",
       "...            ...            ...             ...                   ...   \n",
       "381104    1-2 Year             No         30170.0                  26.0   \n",
       "381105    < 1 Year             No         40016.0                 152.0   \n",
       "381106    < 1 Year             No         35118.0                 160.0   \n",
       "381107   > 2 Years            Yes         44617.0                 124.0   \n",
       "381108    1-2 Year             No         41777.0                  26.0   \n",
       "\n",
       "        Vintage  Response  \n",
       "0           217         1  \n",
       "1           183         0  \n",
       "2            27         1  \n",
       "3           203         0  \n",
       "4            39         0  \n",
       "...         ...       ...  \n",
       "381104       88         0  \n",
       "381105      131         0  \n",
       "381106      161         0  \n",
       "381107       74         0  \n",
       "381108      237         0  \n",
       "\n",
       "[381109 rows x 11 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='Response'>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data['Response'].value_counts().plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 381109 entries, 0 to 381108\n",
      "Data columns (total 11 columns):\n",
      " #   Column                Non-Null Count   Dtype  \n",
      "---  ------                --------------   -----  \n",
      " 0   Gender                381109 non-null  object \n",
      " 1   Age                   381109 non-null  int64  \n",
      " 2   Driving_License       381109 non-null  int64  \n",
      " 3   Region_Code           381109 non-null  float64\n",
      " 4   Previously_Insured    381109 non-null  int64  \n",
      " 5   Vehicle_Age           381109 non-null  object \n",
      " 6   Vehicle_Damage        381109 non-null  object \n",
      " 7   Annual_Premium        381109 non-null  float64\n",
      " 8   Policy_Sales_Channel  381109 non-null  float64\n",
      " 9   Vintage               381109 non-null  int64  \n",
      " 10  Response              381109 non-null  int64  \n",
      "dtypes: float64(3), int64(5), object(3)\n",
      "memory usage: 32.0+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "label=LabelEncoder()\n",
    "ordinal=OrdinalEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Gender']=label.fit_transform(data['Gender'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Vehicle_Damage']=label.fit_transform(data['Vehicle_Damage'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Vehicle_Age'] = ordinal.fit_transform(data['Vehicle_Age'].values.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = data.drop(columns='Response'), data['Response']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler.fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z-cjIbEqaWwN"
   },
   "source": [
    "### Neural Network 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DK6xEmhPa5jj"
   },
   "source": [
    "#### Optimize number of epochs and batch size for NN1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XvheVs3tbB7l"
   },
   "outputs": [],
   "source": [
    "epochs_list= [3, 4, 5]\n",
    "batch_sizes=[32, 64, 128]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "9528/9528 [==============================] - 9s 857us/step - loss: 0.2771 - precision_9: 0.1037 - recall_9: 3.7385e-04\n",
      "Epoch 2/3\n",
      "9528/9528 [==============================] - 8s 858us/step - loss: 0.2703 - precision_9: 0.0000e+00 - recall_9: 0.0000e+00\n",
      "Epoch 3/3\n",
      "9528/9528 [==============================] - 8s 856us/step - loss: 0.2699 - precision_9: 0.0000e+00 - recall_9: 0.0000e+00\n",
      "2382/2382 [==============================] - 2s 638us/step\n",
      "Epoch 1/3\n",
      "4764/4764 [==============================] - 5s 853us/step - loss: 0.2790 - precision_10: 0.0000e+00 - recall_10: 0.0000e+00\n",
      "Epoch 2/3\n",
      "4764/4764 [==============================] - 4s 857us/step - loss: 0.2703 - precision_10: 1.0000 - recall_10: 2.6704e-05\n",
      "Epoch 3/3\n",
      "4764/4764 [==============================] - 4s 853us/step - loss: 0.2698 - precision_10: 0.4545 - recall_10: 5.3407e-04\n",
      "2382/2382 [==============================] - 2s 636us/step\n",
      "Epoch 1/3\n",
      "2382/2382 [==============================] - 3s 872us/step - loss: 0.2785 - precision_11: 0.0339 - recall_11: 1.0681e-04\n",
      "Epoch 2/3\n",
      "2382/2382 [==============================] - 2s 860us/step - loss: 0.2702 - precision_11: 0.0000e+00 - recall_11: 0.0000e+00\n",
      "Epoch 3/3\n",
      "2382/2382 [==============================] - 2s 871us/step - loss: 0.2696 - precision_11: 0.0000e+00 - recall_11: 0.0000e+00\n",
      "2382/2382 [==============================] - 2s 636us/step\n",
      "Epoch 1/4\n",
      "9528/9528 [==============================] - 9s 842us/step - loss: 0.2745 - precision_12: 0.0270 - recall_12: 2.6704e-05\n",
      "Epoch 2/4\n",
      "9528/9528 [==============================] - 8s 849us/step - loss: 0.2704 - precision_12: 0.0000e+00 - recall_12: 0.0000e+00\n",
      "Epoch 3/4\n",
      "9528/9528 [==============================] - 8s 850us/step - loss: 0.2698 - precision_12: 0.0000e+00 - recall_12: 0.0000e+00\n",
      "Epoch 4/4\n",
      "9528/9528 [==============================] - 8s 855us/step - loss: 0.2696 - precision_12: 0.0000e+00 - recall_12: 0.0000e+00\n",
      "2382/2382 [==============================] - 2s 642us/step\n",
      "Epoch 1/4\n",
      "4764/4764 [==============================] - 5s 856us/step - loss: 0.2765 - precision_13: 0.1524 - recall_13: 0.0015\n",
      "Epoch 2/4\n",
      "4764/4764 [==============================] - 4s 857us/step - loss: 0.2702 - precision_13: 0.4483 - recall_13: 6.9430e-04\n",
      "Epoch 3/4\n",
      "4764/4764 [==============================] - 4s 852us/step - loss: 0.2697 - precision_13: 0.5789 - recall_13: 2.9374e-04\n",
      "Epoch 4/4\n",
      "4764/4764 [==============================] - 4s 852us/step - loss: 0.2695 - precision_13: 0.4853 - recall_13: 8.8122e-04\n",
      "2382/2382 [==============================] - 2s 636us/step\n",
      "Epoch 1/4\n",
      "2382/2382 [==============================] - 3s 856us/step - loss: 0.2816 - precision_14: 0.1143 - recall_14: 0.0021\n",
      "Epoch 2/4\n",
      "2382/2382 [==============================] - 2s 868us/step - loss: 0.2706 - precision_14: 0.2500 - recall_14: 2.6704e-05\n",
      "Epoch 3/4\n",
      "2382/2382 [==============================] - 2s 870us/step - loss: 0.2699 - precision_14: 0.4648 - recall_14: 0.0018\n",
      "Epoch 4/4\n",
      "2382/2382 [==============================] - 2s 869us/step - loss: 0.2695 - precision_14: 0.4020 - recall_14: 0.0011\n",
      "2382/2382 [==============================] - 2s 638us/step\n",
      "Epoch 1/5\n",
      "9528/9528 [==============================] - 9s 849us/step - loss: 0.2806 - precision_15: 0.1562 - recall_15: 0.0025\n",
      "Epoch 2/5\n",
      "9528/9528 [==============================] - 8s 859us/step - loss: 0.2711 - precision_15: 0.0000e+00 - recall_15: 0.0000e+00\n",
      "Epoch 3/5\n",
      "9528/9528 [==============================] - 8s 843us/step - loss: 0.2700 - precision_15: 0.3636 - recall_15: 1.0681e-04\n",
      "Epoch 4/5\n",
      "9528/9528 [==============================] - 8s 842us/step - loss: 0.2697 - precision_15: 0.5060 - recall_15: 0.0011\n",
      "Epoch 5/5\n",
      "9528/9528 [==============================] - 8s 843us/step - loss: 0.2695 - precision_15: 0.3548 - recall_15: 2.9374e-04\n",
      "2382/2382 [==============================] - 2s 630us/step\n",
      "Epoch 1/5\n",
      "4764/4764 [==============================] - 5s 848us/step - loss: 0.2801 - precision_16: 0.1505 - recall_16: 8.2781e-04\n",
      "Epoch 2/5\n",
      "4764/4764 [==============================] - 4s 849us/step - loss: 0.2708 - precision_16: 0.5385 - recall_16: 1.8693e-04\n",
      "Epoch 3/5\n",
      "4764/4764 [==============================] - 4s 842us/step - loss: 0.2699 - precision_16: 0.4857 - recall_16: 0.0014\n",
      "Epoch 4/5\n",
      "4764/4764 [==============================] - 4s 841us/step - loss: 0.2696 - precision_16: 0.4320 - recall_16: 0.0014\n",
      "Epoch 5/5\n",
      "4764/4764 [==============================] - 4s 843us/step - loss: 0.2694 - precision_16: 0.4880 - recall_16: 0.0016\n",
      "2382/2382 [==============================] - 2s 633us/step\n",
      "Epoch 1/5\n",
      "2382/2382 [==============================] - 3s 859us/step - loss: 0.2787 - precision_17: 0.2581 - recall_17: 4.2726e-04\n",
      "Epoch 2/5\n",
      "2382/2382 [==============================] - 2s 851us/step - loss: 0.2711 - precision_17: 0.0000e+00 - recall_17: 0.0000e+00\n",
      "Epoch 3/5\n",
      "2382/2382 [==============================] - 2s 853us/step - loss: 0.2703 - precision_17: 0.0000e+00 - recall_17: 0.0000e+00\n",
      "Epoch 4/5\n",
      "2382/2382 [==============================] - 2s 853us/step - loss: 0.2699 - precision_17: 0.0000e+00 - recall_17: 0.0000e+00\n",
      "Epoch 5/5\n",
      "2382/2382 [==============================] - 2s 853us/step - loss: 0.2696 - precision_17: 1.0000 - recall_17: 2.6704e-05\n",
      "2382/2382 [==============================] - 2s 631us/step\n"
     ]
    }
   ],
   "source": [
    "results1 = {}\n",
    "for epoch in epochs_list:\n",
    "    for batch_size in batch_sizes:\n",
    "        model = Sequential()\n",
    "        model.add(Dense(32, activation='relu'))\n",
    "        model.add(Dense(16, activation='relu'))\n",
    "        model.add(Dense(8, activation='relu'))\n",
    "        model.add(Dense(1, activation='sigmoid'))\n",
    "        \n",
    "        model.compile(optimizer=keras.optimizers.Adam(), loss='binary_crossentropy', metrics=[keras.metrics.Precision(), keras.metrics.Recall()])\n",
    "\n",
    "        history = model.fit(X_train, Y_train, epochs=epoch, batch_size=batch_size)\n",
    "\n",
    "        y_pred = model.predict(X_test)\n",
    "        \n",
    "        # Convert predictions to binary (0 or 1)\n",
    "        y_pred_binary = (y_pred > 0.5).astype(int)\n",
    "\n",
    "        f1 = f1_score(Y_test, y_pred_binary)\n",
    "\n",
    "        results1[(epoch, batch_size)] = f1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best combination1: Epochs=4, Batch Size1=128, F1 Score1=0.003869303525365434\n"
     ]
    }
   ],
   "source": [
    "best_combination1 = max(results1, key=results.get)\n",
    "best_epoch1, best_batch_size1 = best_combination1\n",
    "best_f1_score1 = results1[best_combination]\n",
    "\n",
    "print(f\"Best combination1: Epochs={best_epoch1}, Batch Size1={best_batch_size1}, F1 Score1={best_f1_score1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MpnGuxPpakKZ"
   },
   "source": [
    "### Neural Network 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VJZBW-XVbGkJ"
   },
   "source": [
    "#### Optimize number of epochs and batch size for NN2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "id": "7h7-_LdCakKa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "9528/9528 [==============================] - 9s 828us/step - loss: 0.2754 - precision_18: 0.8769 - recall_18: 0.8769\n",
      "Epoch 2/3\n",
      "9528/9528 [==============================] - 8s 836us/step - loss: 0.2705 - precision_18: 0.8772 - recall_18: 0.8772\n",
      "Epoch 3/3\n",
      "9528/9528 [==============================] - 8s 836us/step - loss: 0.2701 - precision_18: 0.8772 - recall_18: 0.8772\n",
      "2382/2382 [==============================] - 2s 685us/step\n",
      "Epoch 1/3\n",
      "4764/4764 [==============================] - 5s 833us/step - loss: 0.2767 - precision_19: 0.8771 - recall_19: 0.8771\n",
      "Epoch 2/3\n",
      "4764/4764 [==============================] - 4s 834us/step - loss: 0.2705 - precision_19: 0.8772 - recall_19: 0.8772\n",
      "Epoch 3/3\n",
      "4764/4764 [==============================] - 4s 833us/step - loss: 0.2699 - precision_19: 0.8772 - recall_19: 0.8772\n",
      "2382/2382 [==============================] - 2s 676us/step\n",
      "Epoch 1/3\n",
      "2382/2382 [==============================] - 3s 841us/step - loss: 0.2816 - precision_20: 0.8771 - recall_20: 0.8771\n",
      "Epoch 2/3\n",
      "2382/2382 [==============================] - 2s 842us/step - loss: 0.2712 - precision_20: 0.8772 - recall_20: 0.8772\n",
      "Epoch 3/3\n",
      "2382/2382 [==============================] - 2s 843us/step - loss: 0.2701 - precision_20: 0.8772 - recall_20: 0.8772\n",
      "2382/2382 [==============================] - 2s 679us/step\n",
      "Epoch 1/4\n",
      "9528/9528 [==============================] - 8s 821us/step - loss: 0.2742 - precision_21: 0.8769 - recall_21: 0.8769\n",
      "Epoch 2/4\n",
      "9528/9528 [==============================] - 8s 823us/step - loss: 0.2705 - precision_21: 0.8772 - recall_21: 0.8772\n",
      "Epoch 3/4\n",
      "9528/9528 [==============================] - 8s 826us/step - loss: 0.2700 - precision_21: 0.8772 - recall_21: 0.8772\n",
      "Epoch 4/4\n",
      "9528/9528 [==============================] - 8s 823us/step - loss: 0.2698 - precision_21: 0.8772 - recall_21: 0.8772\n",
      "2382/2382 [==============================] - 2s 675us/step\n",
      "Epoch 1/4\n",
      "4764/4764 [==============================] - 5s 834us/step - loss: 0.2751 - precision_22: 0.8772 - recall_22: 0.8772\n",
      "Epoch 2/4\n",
      "4764/4764 [==============================] - 4s 831us/step - loss: 0.2704 - precision_22: 0.8772 - recall_22: 0.8772\n",
      "Epoch 3/4\n",
      "4764/4764 [==============================] - 4s 833us/step - loss: 0.2700 - precision_22: 0.8772 - recall_22: 0.8772\n",
      "Epoch 4/4\n",
      "4764/4764 [==============================] - 4s 829us/step - loss: 0.2697 - precision_22: 0.8772 - recall_22: 0.8772\n",
      "2382/2382 [==============================] - 2s 677us/step\n",
      "Epoch 1/4\n",
      "2382/2382 [==============================] - 3s 834us/step - loss: 0.2810 - precision_23: 0.8760 - recall_23: 0.8760\n",
      "Epoch 2/4\n",
      "2382/2382 [==============================] - 2s 838us/step - loss: 0.2715 - precision_23: 0.8772 - recall_23: 0.8772\n",
      "Epoch 3/4\n",
      "2382/2382 [==============================] - 2s 837us/step - loss: 0.2702 - precision_23: 0.8771 - recall_23: 0.8771\n",
      "Epoch 4/4\n",
      "2382/2382 [==============================] - 2s 847us/step - loss: 0.2699 - precision_23: 0.8772 - recall_23: 0.8772\n",
      "2382/2382 [==============================] - 2s 675us/step\n",
      "Epoch 1/5\n",
      "9528/9528 [==============================] - 9s 830us/step - loss: 0.2762 - precision_24: 0.8768 - recall_24: 0.8768\n",
      "Epoch 2/5\n",
      "9528/9528 [==============================] - 8s 827us/step - loss: 0.2706 - precision_24: 0.8772 - recall_24: 0.8772\n",
      "Epoch 3/5\n",
      "9528/9528 [==============================] - 8s 838us/step - loss: 0.2701 - precision_24: 0.8772 - recall_24: 0.8772\n",
      "Epoch 4/5\n",
      "9528/9528 [==============================] - 8s 842us/step - loss: 0.2699 - precision_24: 0.8772 - recall_24: 0.8772\n",
      "Epoch 5/5\n",
      "9528/9528 [==============================] - 8s 839us/step - loss: 0.2698 - precision_24: 0.8772 - recall_24: 0.8772\n",
      "2382/2382 [==============================] - 2s 677us/step\n",
      "Epoch 1/5\n",
      "4764/4764 [==============================] - 5s 829us/step - loss: 0.2770 - precision_25: 0.8760 - recall_25: 0.8760\n",
      "Epoch 2/5\n",
      "4764/4764 [==============================] - 4s 847us/step - loss: 0.2706 - precision_25: 0.8772 - recall_25: 0.8772\n",
      "Epoch 3/5\n",
      "4764/4764 [==============================] - 4s 842us/step - loss: 0.2699 - precision_25: 0.8772 - recall_25: 0.8772\n",
      "Epoch 4/5\n",
      "4764/4764 [==============================] - 4s 849us/step - loss: 0.2697 - precision_25: 0.8772 - recall_25: 0.8772\n",
      "Epoch 5/5\n",
      "4764/4764 [==============================] - 4s 910us/step - loss: 0.2695 - precision_25: 0.8771 - recall_25: 0.8771\n",
      "2382/2382 [==============================] - 2s 688us/step\n",
      "Epoch 1/5\n",
      "2382/2382 [==============================] - 3s 858us/step - loss: 0.2844 - precision_26: 0.8729 - recall_26: 0.8729\n",
      "Epoch 2/5\n",
      "2382/2382 [==============================] - 2s 844us/step - loss: 0.2709 - precision_26: 0.8771 - recall_26: 0.8771\n",
      "Epoch 3/5\n",
      "2382/2382 [==============================] - 2s 858us/step - loss: 0.2703 - precision_26: 0.8772 - recall_26: 0.8772\n",
      "Epoch 4/5\n",
      "2382/2382 [==============================] - 2s 863us/step - loss: 0.2698 - precision_26: 0.8773 - recall_26: 0.8773\n",
      "Epoch 5/5\n",
      "2382/2382 [==============================] - 2s 858us/step - loss: 0.2696 - precision_26: 0.8772 - recall_26: 0.8772\n",
      "2382/2382 [==============================] - 2s 687us/step\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.metrics import f1_score\n",
    "import numpy as np\n",
    "\n",
    "results2 = {}\n",
    "\n",
    "Y_train_one_hot = to_categorical(Y_train, num_classes=2)\n",
    "Y_test_one_hot = to_categorical(Y_test, num_classes=2)\n",
    "\n",
    "for epoch in epochs_list:\n",
    "    for batch_size in batch_sizes:\n",
    "        model = Sequential()\n",
    "        model.add(Dense(32, activation='relu'))\n",
    "        model.add(Dense(16, activation='tanh'))\n",
    "        model.add(Dense(8, activation='relu'))\n",
    "        model.add(Dense(2, activation='softmax'))  \n",
    "        \n",
    "        model.compile(optimizer=keras.optimizers.Adam(), loss='categorical_crossentropy', metrics=[keras.metrics.Precision(), keras.metrics.Recall()])\n",
    "\n",
    "        history = model.fit(X_train, Y_train_one_hot, epochs=epoch, batch_size=batch_size)\n",
    "\n",
    "        y_pred_prob = model.predict(X_test)\n",
    "\n",
    "        # Convert probabilities to binary (0 or 1)\n",
    "        y_pred_binary = np.argmax(y_pred_prob, axis=1)\n",
    "\n",
    "        f1 = f1_score(Y_test, y_pred_binary)\n",
    "\n",
    "        results2[(epoch, batch_size)] = f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best combination2: Epochs=4, Batch Size2=128, F1 Score2=0.0036574870912220313\n"
     ]
    }
   ],
   "source": [
    "best_combination2 = max(results2, key=results.get)\n",
    "best_epoch2, best_batch_size2 = best_combination2\n",
    "best_f1_score2 = results2[best_combination]\n",
    "\n",
    "print(f\"Best combination2: Epochs={best_epoch2}, Batch Size2={best_batch_size2}, F1 Score2={best_f1_score2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "id": "j-uAE7KSbGkJ"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dense, LeakyReLU\n",
    "from tensorflow.keras.models import Sequential"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vo0qlaMNakWQ"
   },
   "source": [
    "### Neural Network 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best combination3: Epochs=4, Batch Size3=128, F1 Score3=0.00021591277124041888\n"
     ]
    }
   ],
   "source": [
    "best_combination3 = max(results3, key=results.get)\n",
    "best_epoch3, best_batch_size3 = best_combination3\n",
    "best_f1_score3 = results3[best_combination]\n",
    "\n",
    "print(f\"Best combination3: Epochs={best_epoch3}, Batch Size3={best_batch_size3}, F1 Score3={best_f1_score3}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bN5SEHuSbJUR"
   },
   "source": [
    "#### Optimize number of epochs and batch size for NN3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "id": "MUZ1-qNSakWQ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "9528/9528 [==============================] - 9s 895us/step - loss: 0.2802 - precision_36: 0.3667 - recall_36: 0.0021\n",
      "Epoch 2/3\n",
      "9528/9528 [==============================] - 9s 899us/step - loss: 0.2732 - precision_36: 0.4741 - recall_36: 0.0032\n",
      "Epoch 3/3\n",
      "9528/9528 [==============================] - 9s 899us/step - loss: 0.2715 - precision_36: 0.4631 - recall_36: 0.0037\n",
      "2382/2382 [==============================] - 2s 652us/step\n",
      "Epoch 1/3\n",
      "4764/4764 [==============================] - 5s 891us/step - loss: 0.2935 - precision_37: 0.1828 - recall_37: 4.5396e-04\n",
      "Epoch 2/3\n",
      "4764/4764 [==============================] - 4s 893us/step - loss: 0.2738 - precision_37: 0.0000e+00 - recall_37: 0.0000e+00\n",
      "Epoch 3/3\n",
      "4764/4764 [==============================] - 4s 890us/step - loss: 0.2726 - precision_37: 0.0000e+00 - recall_37: 0.0000e+00\n",
      "2382/2382 [==============================] - 2s 953us/step\n",
      "Epoch 1/3\n",
      "2382/2382 [==============================] - 3s 918us/step - loss: 0.2901 - precision_38: 0.2857 - recall_38: 3.2044e-04\n",
      "Epoch 2/3\n",
      "2382/2382 [==============================] - 2s 914us/step - loss: 0.2716 - precision_38: 0.0000e+00 - recall_38: 0.0000e+00\n",
      "Epoch 3/3\n",
      "2382/2382 [==============================] - 2s 913us/step - loss: 0.2703 - precision_38: 0.0000e+00 - recall_38: 0.0000e+00\n",
      "2382/2382 [==============================] - 2s 658us/step\n",
      "Epoch 1/4\n",
      "9528/9528 [==============================] - 9s 909us/step - loss: 0.2808 - precision_39: 0.0791 - recall_39: 6.6759e-04\n",
      "Epoch 2/4\n",
      "9528/9528 [==============================] - 9s 908us/step - loss: 0.2709 - precision_39: 0.3333 - recall_39: 5.3407e-05\n",
      "Epoch 3/4\n",
      "9528/9528 [==============================] - 9s 906us/step - loss: 0.2702 - precision_39: 0.1250 - recall_39: 2.6704e-05\n",
      "Epoch 4/4\n",
      "9528/9528 [==============================] - 9s 905us/step - loss: 0.2699 - precision_39: 0.6667 - recall_39: 5.3407e-05\n",
      "2382/2382 [==============================] - 2s 656us/step\n",
      "Epoch 1/4\n",
      "4764/4764 [==============================] - 5s 906us/step - loss: 0.2796 - precision_40: 0.2500 - recall_40: 3.4715e-04\n",
      "Epoch 2/4\n",
      "4764/4764 [==============================] - 4s 913us/step - loss: 0.2718 - precision_40: 0.0000e+00 - recall_40: 0.0000e+00\n",
      "Epoch 3/4\n",
      "4764/4764 [==============================] - 4s 913us/step - loss: 0.2707 - precision_40: 0.0000e+00 - recall_40: 0.0000e+00\n",
      "Epoch 4/4\n",
      "4764/4764 [==============================] - 4s 940us/step - loss: 0.2702 - precision_40: 0.0000e+00 - recall_40: 0.0000e+00\n",
      "2382/2382 [==============================] - 2s 672us/step\n",
      "Epoch 1/4\n",
      "2382/2382 [==============================] - 3s 921us/step - loss: 0.2871 - precision_41: 0.2824 - recall_41: 6.4089e-04\n",
      "Epoch 2/4\n",
      "2382/2382 [==============================] - 2s 979us/step - loss: 0.2713 - precision_41: 0.0000e+00 - recall_41: 0.0000e+00\n",
      "Epoch 3/4\n",
      "2382/2382 [==============================] - 2s 919us/step - loss: 0.2705 - precision_41: 0.0000e+00 - recall_41: 0.0000e+00\n",
      "Epoch 4/4\n",
      "2382/2382 [==============================] - 2s 945us/step - loss: 0.2702 - precision_41: 0.0000e+00 - recall_41: 0.0000e+00\n",
      "2382/2382 [==============================] - 2s 729us/step\n",
      "Epoch 1/5\n",
      "9528/9528 [==============================] - 10s 944us/step - loss: 0.3057 - precision_42: 0.1860 - recall_42: 0.0049\n",
      "Epoch 2/5\n",
      "9528/9528 [==============================] - 9s 903us/step - loss: 0.2717 - precision_42: 0.3500 - recall_42: 9.3463e-04\n",
      "Epoch 3/5\n",
      "9528/9528 [==============================] - 9s 903us/step - loss: 0.2709 - precision_42: 0.2381 - recall_42: 1.3352e-04\n",
      "Epoch 4/5\n",
      "9528/9528 [==============================] - 9s 903us/step - loss: 0.2705 - precision_42: 0.3800 - recall_42: 5.0737e-04\n",
      "Epoch 5/5\n",
      "9528/9528 [==============================] - 9s 908us/step - loss: 0.2702 - precision_42: 0.4490 - recall_42: 0.0012\n",
      "2382/2382 [==============================] - 2s 680us/step\n",
      "Epoch 1/5\n",
      "4764/4764 [==============================] - 5s 910us/step - loss: 0.2790 - precision_43: 0.0000e+00 - recall_43: 0.0000e+00\n",
      "Epoch 2/5\n",
      "4764/4764 [==============================] - 4s 921us/step - loss: 0.2715 - precision_43: 0.0000e+00 - recall_43: 0.0000e+00\n",
      "Epoch 3/5\n",
      "4764/4764 [==============================] - 4s 905us/step - loss: 0.2709 - precision_43: 0.0000e+00 - recall_43: 0.0000e+00\n",
      "Epoch 4/5\n",
      "4764/4764 [==============================] - 4s 910us/step - loss: 0.2704 - precision_43: 0.0000e+00 - recall_43: 0.0000e+00\n",
      "Epoch 5/5\n",
      "4764/4764 [==============================] - 4s 904us/step - loss: 0.2700 - precision_43: 0.0000e+00 - recall_43: 0.0000e+00\n",
      "2382/2382 [==============================] - 2s 657us/step\n",
      "Epoch 1/5\n",
      "2382/2382 [==============================] - 3s 929us/step - loss: 0.2858 - precision_44: 0.2174 - recall_44: 1.3352e-04\n",
      "Epoch 2/5\n",
      "2382/2382 [==============================] - 2s 910us/step - loss: 0.2714 - precision_44: 0.0000e+00 - recall_44: 0.0000e+00\n",
      "Epoch 3/5\n",
      "2382/2382 [==============================] - 2s 916us/step - loss: 0.2704 - precision_44: 0.0000e+00 - recall_44: 0.0000e+00\n",
      "Epoch 4/5\n",
      "2382/2382 [==============================] - 2s 917us/step - loss: 0.2701 - precision_44: 0.0000e+00 - recall_44: 0.0000e+00\n",
      "Epoch 5/5\n",
      "2382/2382 [==============================] - 2s 904us/step - loss: 0.2697 - precision_44: 0.0000e+00 - recall_44: 0.0000e+00\n",
      "2382/2382 [==============================] - 2s 662us/step\n"
     ]
    }
   ],
   "source": [
    "results3 = {}\n",
    "for epoch in epochs_list:\n",
    "    for batch_size in batch_sizes:\n",
    "        model = Sequential()\n",
    "        model.add(Dense(16, activation=LeakyReLU(alpha=0.01)))\n",
    "        model.add(Dense(8, activation='tanh'))\n",
    "        model.add(Dense(4, activation=LeakyReLU(alpha=0.02)))\n",
    "        model.add(Dense(2, activation=LeakyReLU(alpha=0.02)))\n",
    "        model.add(Dense(1, activation='sigmoid'))\n",
    "        \n",
    "        model.compile(optimizer=keras.optimizers.Adam(), loss='binary_crossentropy', metrics=[keras.metrics.Precision(), keras.metrics.Recall()])\n",
    "\n",
    "        history = model.fit(X_train, Y_train, epochs=epoch, batch_size=batch_size)\n",
    "\n",
    "        y_pred = model.predict(X_test)\n",
    "        \n",
    "        # Convert predictions to binary (0 or 1)\n",
    "        y_pred_binary = (y_pred > 0.5).astype(int)\n",
    "\n",
    "        f1 = f1_score(Y_test, y_pred_binary)\n",
    "\n",
    "        results3[(epoch, batch_size)] = f1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VD2UF-8AbJUS"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "21ggHDTEa17b"
   },
   "source": [
    "## Evaluate the three NNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MHD7htN7a1xB"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FUb0uPdDbUmc"
   },
   "source": [
    "## Results analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "id": "n74eAnwPbUmd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best combination1: Epochs=4, Batch Size1=128, F1 Score1=0.003869303525365434\n",
      "Best combination2: Epochs=4, Batch Size2=128, F1 Score2=0.0036574870912220313\n",
      "Best combination3: Epochs=4, Batch Size3=128, F1 Score3=0.00021591277124041888\n"
     ]
    }
   ],
   "source": [
    "print(f\"Best combination1: Epochs={best_epoch1}, Batch Size1={best_batch_size1}, F1 Score1={best_f1_score1}\")\n",
    "print(f\"Best combination2: Epochs={best_epoch2}, Batch Size2={best_batch_size2}, F1 Score2={best_f1_score2}\")\n",
    "print(f\"Best combination3: Epochs={best_epoch3}, Batch Size3={best_batch_size3}, F1 Score3={best_f1_score3}\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
